@misc{AmazingFeatureEngineeringShortGuide,
  title = {Amazing-{{Feature-Engineering}}/{{A Short Guide}} for {{Feature Engineering}} and {{Feature Selection}}.Md at Master {$\cdot$} Ashishpatel26/{{Amazing-Feature-Engineering}}},
  journal = {GitHub},
  urldate = {2023-11-13},
  abstract = {Feature engineering is the process of using domain knowledge to extract features from raw data via data mining techniques. These features can be used to improve the performance of machine learning ...},
  howpublished = {https://github.com/ashishpatel26/Amazing-Feature-Engineering/blob/master/A\%20Short\%20Guide\%20for\%20Feature\%20Engineering\%20and\%20Feature\%20Selection.md},
  langid = {english}
}

@book{bainIntroductionProbabilityMathematical1992a,
  title = {Introduction to Probability and Mathematical Statistics},
  author = {Bain, Lee J. and Engelhardt, Max},
  year = {1992},
  series = {The {{Duxbury}} Advanced Series in Statistics and Decision Sciences},
  edition = {2nd ed},
  publisher = {PWS-KENT Pub},
  address = {Boston},
  isbn = {978-0-534-92930-5 978-0-534-98563-9},
  langid = {english},
  lccn = {QA273 .B2546 1991},
  keywords = {Mathematical statistics,Probabilities},
  file = {/home/hugo/Zotero/storage/KVR8PLP9/Bain and Engelhardt - 1992 - Introduction to probability and mathematical stati.pdf}
}

@misc{BookStatisticalProofs,
  title = {The {{Book}} of {{Statistical Proofs}}},
  journal = {The Book of Statistical Proofs},
  urldate = {2023-11-14},
  abstract = {The Book of Statistical Proofs -- a centralized, open and collaboratively edited archive of statistical theorems for the computational sciences},
  howpublished = {https://statproofbook.github.io/},
  langid = {english},
  file = {/home/hugo/Zotero/storage/CHW83KCG/statproofbook.github.io.html}
}

@misc{boschenAnswerPSDScailing2021,
  title = {Answer to "about {{PSD}} Scailing Factor"},
  author = {Boschen, Dan},
  year = {2021},
  month = dec,
  journal = {Signal Processing Stack Exchange},
  urldate = {2023-11-28},
  file = {/home/hugo/Zotero/storage/R3DEAP4D/about-psd-scailing-factor.html}
}

@article{brauchlerDistinguishingGeometricallyIdentical2022,
  title = {Distinguishing Geometrically Identical Instruments: {{Possibilistic}} Identification of Material Parameters in a Parametrically Model Order Reduced Finite Element Model of a Classical Guitar},
  shorttitle = {Distinguishing Geometrically Identical Instruments},
  author = {Brauchler, Alexander and Hose, Dominik and Ziegler, Pascal and Hanss, Michael and Eberhard, Peter},
  year = {2022},
  month = sep,
  journal = {Journal of Sound and Vibration},
  volume = {535},
  pages = {117071},
  issn = {0022-460X},
  doi = {10.1016/j.jsv.2022.117071},
  urldate = {2023-10-16},
  abstract = {The identification of material parameters of classical guitars is particularly interesting as the orthotropic material parameters of wood vary largely and lead to hearable differences even in seemingly identical instruments. Identification methods intended to achieve this task commonly try to fit, e.g.,~finite element models to experimental data by minimizing a given objective function, and typically return precise parameter values. However, such one-point estimators do not contain much information with respect to the uncertainty that may remain regarding the true values~--~irrespective of whether such a ground truth can be assumed at all. Model updating techniques that also intend to quantify these uncertainties typically require the practitioner to specify a statistical model of the experiment, which is not easily formulated. Moreover, virtually all uncertainty quantification techniques require a high number of model evaluations, which is diametrically opposed to the long evaluation times of high-fidelity finite element models. In this contribution, an alternative technique for uncertainty quantification based on possibility theory is proposed and applied to a classical guitar. Only requiring the practitioner to specify an objective function, which may be identical to the one used to find point estimates, it is readily accessible and straightforward to apply. Great emphasis is put on the construction of a high-fidelity guitar model and the construction of suitable surrogate models via parametric model order reduction based on Krylov subspace methods, which drastically reduces the number of degrees of freedom in the surrogate model of the finite element model while maintaining the parameter dependency. In this manner, model order reduction allows for significant speedups of the model evaluations and, more importantly here, facilitates the uncertainty quantification in the first place. It is demonstrated how this scheme is able to find regions of plausible parameter values of the guitar and how one may distinguish quasi-identical instruments with great confidence, e.g.,~due to the disjointness of such regions, compared to the moderate confidence implied by more or less disagreeing point estimates. Although motivated by the material parameter identification of guitars, the presented method yields great potential for applicability to inverse problems tackled with finite element models in general.},
  keywords = {Classical guitar,Finite element method,Parameter identification,Parametric model order reduction,Uncertainty quantification},
  file = {/home/hugo/Zotero/storage/SJS8752P/Brauchler et al. - 2022 - Distinguishing geometrically identical instruments.pdf}
}

@article{buenCOMPARINGSOUNDGOLDEN2005,
  title = {{{COMPARING THE SOUND O F GOLDEN AGE AND MODERN VIOLINS}}: {{LONG-TIME-AVERAGE SPECTRA}}},
  shorttitle = {{{COMPARING THE SOUND O F GOLDEN AGE AND MODERN VIOLINS}}},
  author = {Buen, Anders},
  year = {2005},
  month = jul,
  abstract = {Recordings of the sound spectra produced by violins made by Antonio Stradivari (1 5), Giuseppe Guameri del Gesu (1 5), and 18 contemporary makers were analyzed and compared In general, the sound produced by the 30 violins crafted by the two great Italian masters is very strong in the region from about C\#q to G4 (274 to 41 0 Hz) and signij7cantly stronger in the highrfiequency regionfrom to G7 (2901 to 3073 Hz) and from B, to G\#8 (3868 to 6494 Hz). The particular group of modem violins we ana-lyzed had relatively equal or stronger fundamentals at very low notes below Cq ({$<$}260 Hz), in the mid-frequency region A4 to F, (440 to 2793 Hz), and at very high frequencies ({$>$}6.5 H z) . Overall, the sound produced by the violins of Stradivari and Guameri was darker, less nasal, somewhat stronger in the high-brightness region, and possibly less sharp than was typical of the modem violins.},
  file = {/home/hugo/Zotero/storage/PCY2UA9Z/Buen - 2005 - COMPARING THE SOUND O F GOLDEN AGE AND MODERN VIOL.pdf}
}

@incollection{caetanoAudioContentDescriptors2019,
  title = {Audio {{Content Descriptors}} of {{Timbre}}},
  booktitle = {Timbre: {{Acoustics}}, {{Perception}}, and {{Cognition}}},
  author = {Caetano, Marcelo and Saitis, Charalampos and Siedenburg, Kai},
  editor = {Siedenburg, Kai and Saitis, Charalampos and McAdams, Stephen and Popper, Arthur N. and Fay, Richard R.},
  year = {2019},
  volume = {69},
  pages = {297--333},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-14832-4_11},
  urldate = {2023-11-09},
  isbn = {978-3-030-14831-7 978-3-030-14832-4},
  langid = {english},
  file = {/home/hugo/Zotero/storage/6H5HZJKT/Caetano et al. - 2019 - Audio Content Descriptors of Timbre.pdf}
}

@article{cattaniValueCreationKnowledge2013,
  title = {Value {{Creation}} and {{Knowledge Loss}}: {{The Case}} of {{Cremonese Stringed Instruments}}},
  shorttitle = {Value {{Creation}} and {{Knowledge Loss}}},
  author = {Cattani, Gino and Dunbar, Roger L. M. and Shapira, Zur},
  year = {2013},
  month = jun,
  journal = {Organization Science},
  volume = {24},
  number = {3},
  pages = {813--830},
  publisher = {INFORMS},
  issn = {1047-7039},
  doi = {10.1287/orsc.1120.0768},
  urldate = {2023-10-16},
  abstract = {To understand how the value of cultural products is determined, one must consider how evaluations evolve over time and have an impact on the conditions supporting knowledge development. If evaluations do not fully recognize the potential value of a cultural product, the associated knowledge---especially tacit knowledge---may be lost rather than passed on, thus jeopardizing subsequent attempts to reproduce the valued product. We examine these dynamics by studying how value was attributed to Cremonese stringed instruments. The value the Cremonese masters created was first recognized in the 16th century, and in the early 18th century, new methods to strengthen instrument sound and sonority were developed. However, the value of these new developments was not widely recognized until the 19th century, when, in evaluating musical performance, performers, critics, and public audiences took over from royal courts, and they selected Cremonese instruments as the best for performing the emerging Romantic music. We consider how the dynamics of value determination over time have implications for knowledge management processes.},
  keywords = {apprenticeship,field,historical case,knowledge loss,stringed instruments,value creation},
  file = {/home/hugo/Zotero/storage/63QA6CPS/Cattani et al. - 2013 - Value Creation and Knowledge Loss The Case of Cre.pdf}
}

@misc{CegemeIracema,
  title = {Cegeme/Iracema},
  urldate = {2023-12-14},
  howpublished = {https://github.com/cegeme/iracema/tree/develop}
}

@inproceedings{charlesViolinTimbreSpace2006,
  title = {Violin Timbre Space Features},
  booktitle = {{{IET Irish Signals}} and {{Systems Conference}} ({{ISSC}} 2006)},
  author = {Charles, J.A. and Fitzgerald, D. and Coyle, E.},
  year = {2006},
  volume = {2006},
  pages = {471--476},
  publisher = {IEE},
  address = {Dublin, Ireland},
  doi = {10.1049/cp:20060481},
  urldate = {2023-10-25},
  isbn = {978-0-86341-665-1},
  langid = {english},
  file = {/home/hugo/Zotero/storage/KYSMK5US/Charles et al. - 2006 - Violin timbre space features.pdf}
}

@misc{ComprehensiveGuideFeature,
  title = {Comprehensive {{Guide}} on {{Feature Selection}}},
  urldate = {2023-11-13},
  abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from multiple data sources},
  howpublished = {https://kaggle.com/code/prashant111/comprehensive-guide-on-feature-selection},
  langid = {english},
  file = {/home/hugo/Zotero/storage/MSRS85V9/comprehensive-guide-on-feature-selection.html}
}

@article{decheveigneYINFundamentalFrequency2002a,
  title = {{{YIN}}, a Fundamental Frequency Estimator for Speech and Musica)},
  author = {{de Cheveigne}, Alain and Kawahara, Hideki},
  year = {2002},
  journal = {J. Acoust. Soc. Am.},
  volume = {111},
  number = {4},
  langid = {english},
  file = {/home/hugo/Zotero/storage/9R83Z9QT/de Cheveigne and Kawahara - 2002 - YIN, a fundamental frequency estimator for speech .pdf}
}

@inproceedings{eronenMusicalInstrumentRecognition2000,
  title = {Musical Instrument Recognition Using Cepstral Coefficients and Temporal Features},
  booktitle = {2000 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}. {{Proceedings}} ({{Cat}}. {{No}}.{{00CH37100}})},
  author = {Eronen, A. and Klapuri, A.},
  year = {2000},
  month = jun,
  volume = {2},
  pages = {II753-II756 vol.2},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2000.859069},
  urldate = {2024-05-07},
  abstract = {In this paper, a system for pitch independent musical instrument recognition is presented. A wide set of features covering both spectral and temporal properties of sounds was investigated, and their extraction algorithms were designed. The usefulness of the features was validated using test data that consisted of 1498 samples covering the full pitch ranges of 30 orchestral instruments from the string, brass and woodwind families, played with different techniques. The correct instrument family was recognized with 94\% accuracy and individual instruments in 80\% of cases. These results are compared to those reported in other work. Also, utilization of a hierarchical classification framework is considered.},
  keywords = {Algorithm design and analysis,Cepstral analysis,Data mining,Instruments,Laboratories,Multiple signal classification,Music,printed,Signal analysis,Signal processing algorithms,Testing},
  file = {/home/hugo/Zotero/storage/RH2LRRU2/859069.html}
}

@article{essidMusicalInstrumentRecognition2006,
  title = {Musical Instrument Recognition by Pairwise Classification Strategies},
  author = {Essid, S. and Richard, G. and David, B.},
  year = {2006},
  month = jul,
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  volume = {14},
  number = {4},
  pages = {1401--1412},
  issn = {1558-7916},
  doi = {10.1109/TSA.2005.860842},
  urldate = {2024-08-30},
  abstract = {Musical instrument recognition is an important aspect of music information retrieval. In this paper, statistical pattern recognition techniques are utilized to tackle the problem in the context of solo musical phrases. Ten instrument classes from different instrument families are considered. A large sound database is collected from excerpts of musical phrases acquired from commercial recordings translating different instrument instances, performers, and recording conditions. More than 150 signal processing features are studied including new descriptors. Two feature selection techniques, inertia ratio maximization with feature space projection and genetic algorithms are considered in a class pairwise manner whereby the most relevant features are fetched for each instrument pair. For the classification task, experimental results are provided using Gaussian mixture models (GMMs) and support vector machines (SVMs). It is shown that higher recognition rates can be reached with pairwise optimized subsets of features in association with SVM classification using a radial basis function kernel.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/home/hugo/Zotero/storage/HEUVST96/Essid et al. - 2006 - Musical instrument recognition by pairwise classif.pdf}
}

@article{farinaRealisationVirtualMusical1995,
  title = {Realisation of "Virtual" Musical Instruments: Measurements of the {{Impulse Response}} of {{Violins}} Using {{MLS}} Technique},
  shorttitle = {Realisation of "Virtual" Musical Instruments},
  author = {Farina, Angelo and Langhoff, Andreas and Tronchin, Lamberto},
  year = {1995},
  month = jan,
  abstract = {In this paper the realisation of "virtual" musical instruments is analysed, in which the instruments are treated as linear systems, characterised by their impulse response. Various measurements techniques of the impulse response have been tested, employing different transducers and numerical analysis. The better one resulted the direct Maximum Length Sequence excitation signal, applied to the bridge of the violin by a current-to-force transducer. The acoustic pressure radiated from the violin's body is then sampled by a microphone located in an anechoic chamber, and the Impulse Response is obtained by cross-correlation of the acoustic signal with the excitation signal. The impulse responses measured with the technique presented in this paper contain all the timbric and reverberant characteristics of the violin. Langhoff already developed a rating technique that make it possible to extract objective informations about the timbric quality of violins (1): the scope of the present work is to evaluate also the reverberant quality of the instruments. Furthermore, the measurement of the impulse response enables the creation of a "virtual" violin, which is a numerical filter that applied by convolution to an "anechoic" signal add to it all its information. The techniques to obtain such samples of "anechoic" input signals are also discussed here.},
  file = {/home/hugo/Zotero/storage/3EMNA439/Farina et al. - 1995 - Realisation of virtual musical instruments meas.pdf}
}

@inproceedings{farinaSubjectiveComparisonsVirtual2000,
  title = {Subjective {{Comparisons}} of ``{{Virtual}}'' {{Violins Obtained}} by {{Convolution}}},
  author = {Farina, A. and Langhoff, A. and Tronchin, L.},
  year = {2000},
  urldate = {2024-05-21},
  abstract = {The subjective judgements on ancient violin are influenced by non acoustic phenomena, as the knowledge of the violin maker, the vision of the instruments and, for the performer, also the touch of the violin, the degree of conservation of the instrument, etc. Listening to ``virtual'' instruments let us to consider subjective evaluations in rapid sequences based only on acoustic events, without variation of other parameters, as performer playing, or kind of music, room acoustic, etc. During this study, four ``anechoic'' music samples (Paganini, Bach, Mozart, Paganini), kindly played by Maestro Marco Fornaciari, were digitally recorded. He played on 3 different instruments in an anechoic chamber. Simultaneously the violin bridgeexcitation and the acoustic response of the sound chest were digitally recorded on a two channels DAT , using a velocity transducer and a free field microphone. Subjective pair tests were conducted, to determine the validity of the ``virtual instrument'' technique for comparison with recordings made with the actual different instruments. An arbitrary sequence of ``real'' acoustic signal pairs, convoluted pairs and control pairs (``truly equal'' and ``truly different'' pairs) was created. The results of the listening tests confirmed the excellent degree of similarity between the direct acoustic recording and convolution technique; furthermore the analysis of the two control groups validates the significativity of the test. These results suggest that it will be possible to correlate subjective evaluations and physical characteristics of the instruments, by using the convolution technique. 1 Convolution by Frequency Domain Processing Since some years specialised hardware to perform continuous delayed convolution exist [1], but they are still very expensive and don't allow easily to digitally transfer the input and output signals on a PC. These devices are using Frequency Domain Processing with large blocks of data, resulting in a delay that is 3-4 times larger than the impulse response length. Time domain processing DSP boards, on the other hand, are capable of time domain convolution with no delay, but are limited to a few thousands of filter taps (in the better cases). In this work a software fast convolver (Aurora), running on a standard PC hardware, was employed. The Aurora system make use of a very different approach: both the input and output data files are stored on the hard disk in standard WAV format and, once convolution is performed, comparative tests can easily be conducted with just a ``point and click'' delay. Convolution is performed through the well known ``select-save'' algorithm [2]: details and performances of the convolution software were already published in [3]. Now the program has been extended to longer impulse responses (up to 200000 taps) and speeded up a lot. This way it can handle the binaural reverberation simulation of large acoustic spaces [4]. 2. Validation of the inverse filtering to recover the ``anechoic'' input signal To validate the procedure of extracting the ``anechoic'' impulse signal from the microphone recordings taken in an anechoic chamber, a preliminary test was conducted. 4 ``anechoic'' input signals were recovered from microphone recordings of 4 different music pieces (2 of Paganini, one of Bach and the last of Mozart), with the technique already described in [5]; then they were convoluted with the impulse response of the same violin. These signals resulted almost indistinguishable from the original ones when listened in a normally reverberant space, whilst in headphone listening a little increase in the reverberation can be evidenced for the convoluted signals, for the reasons explained in [5]. In any case, the timbric perception was almost perfect, and this is the most important aspect for violins. 3. Subjective Test to Compare the Acoustic Quality of Violins For a long time many peoples were studying the acoustic characterisation of musical instruments using conventional methods (i.e., by comparing the music played on different instruments); today, by using the novel convolution technique, it is possible to correlate the objective acoustic properties of violins with subjective evaluations without the need to collect dozens of performance recordings over different instruments. To test the feasibility and robustness of the new technique, a large pair comparison test was conducted, with the aim to evaluate the subjective perceptibility of differences among different instruments. Four different Instruments were employed for this test: the first is an ancient Violin (Klotz), kindly offered from the Cremona's making school, the second is an other ancient Violin, (Calcanius), and the last violin is a Langhoff. At the end, a very different timbric Instrument, a viola, was utilised to create ``really different'' pairs. Two ``anechoic'' samples were used for the test: a music piece of Paganini and one of Bach. The music pieces were kindly played by Maestro Marco Fornaciari. The ``anechoic'' input samples were obtained by deconvolution of the impulse response of the Langhoff's violin from the pressure signals directly recorded in anechoic chamber during the music playing, as already described in [5]. The ``anechoic'' input samples so obtained were convoluted with the measured impulse responses of the different instruments. Thus 3 pairs of convoluted samples were obtained. At the other hand, 3 pairs of ``microphonic pieces'' were added to the set of data, in which the presentation order was randomly shuffled. To obtain comparison data, two ``control groups'' each of 3 pairs of samples were mixed with the ``true comparisons'' set: 3 ``really equal'' pairs (obtained playing twice the same sample) and 3 ``really different'' pairs (obtained with convoluted pairs in which each violin is compared to the viola). The same iteration was repeated for each kind of music: Paganini and Bach, in order to get 24 total pairs. 9 subjects were asked to listen to the 24 pairs, filling up for each pair the following questionnaire: Pair no. .......... Are the two violins A and B the same? yes {$\pi$} no {$\pi$} If Your response is no, explain why: a lot (-2) slightly (-1) no difference (0) slightly (+1) a lot (+2) A is better {$\pi$} {$\pi$} {$\pi$} {$\pi$} {$\pi$} B is better A has more pronounced bass {$\pi$} {$\pi$} {$\pi$} {$\pi$} {$\pi$} B has more pronounced bass A has more pronounced treble {$\pi$} {$\pi$} {$\pi$} {$\pi$} {$\pi$} B has more pronounced treble A is softer {$\pi$} {$\pi$} {$\pi$} {$\pi$} {$\pi$} B is softer 3.1 Subjective results The following table summarises the results of the first question (percentage of ``equality''): Convoluted samples Microphonic samples Truly equal samples Truly different samples 14.6 \% 12.5 \% 75 \% 0 \% These percentages show that convoluted simulations have actually almost the same degree of dissimilarity as microphonic recording. But the truly equal and truly different samples are clearly recognised by the listeners. Analysing the other 4 responses, the following three tables are obtained for the three violins studied, showing the average value and the standard deviation of each response: Langhoff Violin Conv. samples Microph. samples Equal samples Different samples better -0.69 {\textpm} 0.83 -0.28 {\textpm} 1.01 0.0 {\textpm} 0.71 0.37 {\textpm} 1.41 pronounced bass -0.28 {\textpm} 0.81 -0.31{\textpm} 0.98 0.0 {\textpm} 0.35 -0.56 {\textpm} 1.22 pronounced treble -0.37 {\textpm} 1.01 0.0 {\textpm} 1.05 0.0 {\textpm} 0.50 1.44 {\textpm} 0.93 soft -0.16 {\textpm} 1.18 -0.19 {\textpm} 1.11 0.06 {\textpm} 0.56 -0.75 {\textpm} 0.97 Klotz Violin Conv. samples Microph. samples Equal samples Different samples better -0.16 {\textpm} 1.17 -0.03 {\textpm} 1.01 0.19 {\textpm} 0.39 0.75 {\textpm} 1.48 pronounced bass 0.34 {\textpm} 0.93 0.12 {\textpm} 1.25 -0.13 {\textpm} 0.33 -1.06 {\textpm} 0.97 pronounced treble -0.19 {\textpm} 1.03 -0.09 {\textpm} 1.05 0.13 {\textpm} 0.48 1.25 {\textpm} 0.83 soft 0.03 {\textpm} 1.03 0.09 {\textpm} 1.06 -0.06 {\textpm} 0.43 -0.75 {\textpm} 1.20 Calcanius Violin Conv. samples Microph. samples Equal samples Different samples better 0.44 {\textpm} 1.05 0.72 {\textpm} 1.17 -0.13 {\textpm} 0.48 0.12 {\textpm} 1.05 pronounced bass -0.03 {\textpm} 1.10 0.16 {\textpm} 1.05 -0.19 {\textpm} 0.53 -1.06 {\textpm} 0.97 pronounced treble 0.19 {\textpm} 0.93 0.47 {\textpm} 1.06 0.19 {\textpm} 0.53 1.25 {\textpm} 0.83 soft 0.16 {\textpm} 1.09 0.06 {\textpm} 1.17 -0.13 {\textpm} 0.60 -0.19 {\textpm} 1.18 It can be observed that the values of convoluted samples pairs are very near to those obtained from microphonic samples, as the differences are always lower than the standard deviations. On the other hand, the control groups show very different responses, that approach almost perfectly zero for the truly equal pairs, and exhibit extreme values for the truly different pairs. This effect can be observed in a more evident way by looking at the graphs of fig. 1. The truly equal pairs always show a strong peak on the ``0'' (equality), while the truly different pairs show an evident trend toward an extreme of the scale. This is due to the fact that actually the viola is a very bad instrument compared to three violins (question n. 1), it has more pronounced bass (question 2), it does not have treble (question 3), and is certainly softer than the violins (question 4).},
  file = {/home/hugo/Zotero/storage/PDF9C6PA/Farina et al. - Subjective Comparisons of “Virtual” Violins Obtain.pdf}
}

@misc{FeynmanLecturesPhysics,
  title = {The {{Feynman Lectures}} on {{Physics}}},
  urldate = {2024-02-21},
  howpublished = {https://www.feynmanlectures.caltech.edu/}
}

@book{fletcherPhysicsMusicalInstruments1998,
  title = {The {{Physics}} of {{Musical Instruments}}},
  author = {Fletcher, Neville H. and Rossing, Thomas D.},
  year = {1998},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-21603-4},
  urldate = {2024-06-02},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4419-3120-7 978-0-387-21603-4},
  langid = {english},
  keywords = {Dulcimer,Gong,Harp,Horn,Pi,Piano,Tar,Vibration,Wave},
  file = {/home/hugo/Zotero/storage/G3VYS8MR/Fletcher and Rossing - 1998 - The Physics of Musical Instruments.pdf}
}

@inproceedings{fritzBilbaoProjectSearching2021,
  title = {The {{Bilbao}} Project: Searching for Relationships between Sound and Playing Properties of Violins with Their Construction Parameters},
  shorttitle = {The {{Bilbao}} Project},
  booktitle = {Conference on {{Sound Perception}}},
  author = {Fritz, Claudia and Salvador, V{\'i}ctor and Stoppani, George},
  year = {2021},
  month = sep,
  urldate = {2024-06-14},
  abstract = {The Bilbao project aimed at relating intrinsic characteristics of the materials (wood density and stiffness) and some geometric characteristics of the violin's constituent part (thicknesses of the plates) with the tonal qualities of the complete violins. To this end, six instruments were carefully built at the Bilbao making school: three instruments with normal backs, each paired with a pliant (thin), normal or resistant (thick) top; similarly, three with normal tops, each paired with a pliant, normal or resistant back. The two examples of normal top paired with normal back serve as a control. Wood for tops and backs were closely matched in density and sound speeds-all tops and backs from the same trees. Greater control was achieved by having all plates and scrolls cut by CNC routers, using the Huberman Stradivari model. The outside surface was not changed as the graduation was performed entirely on the inside surface. In addition, another six instruments were built by six established makers, following a similar procedure but with less constraints on the choice of wood (not the same trees as for the Bilbao set though a similar density was imposed) and on the graduation of the routed plates which was left totally free (but ended in the same range of thicknesses). Finally, another violin built with a very different profile but made by one of the established maker was added to the pool as an outlier. These thirteen violins were then evaluated by twenty players during a free categorisation task and by about 70 listeners (31 violin makers, 26 bow players and 15 others) during a listening test in the Bilbao conservatory auditorium. The tests show very large differences in terms of timbre, playability and volume between the violins, and these differences will be discussed in the light of their construction parameters.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/F4E43HWS/hal-03446713v1.html}
}

@article{fritzListenerEvaluationsNew2017,
  title = {Listener Evaluations of New and {{Old Italian}} Violins},
  author = {Fritz, Claudia and Curtin, Joseph and Poitevineau, Jacques and Tao, Fan-Chia},
  year = {2017},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {21},
  pages = {5395--5400},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1619443114},
  urldate = {2023-05-19},
  abstract = {Old Italian violins are routinely credited with playing qualities supposedly unobtainable in new instruments. These qualities include the ability to project their sound more effectively in a concert hall -- despite seeming relatively quiet under the ear of the player, compared with new violins. While researchers have long tried to explain the ``mystery'' of Stradivari{\quotedblbase}s sound, it is only recently that studies have addressed the fundamental assumption of tonal superiority. Results from two studies show that under blind conditions experienced violinists tend to prefer playing new violins over Old Italians. Moreover, they are unable to tell new from old at better than chance levels. The current study explores the relative merits of Stradivari and new violins from the perspective of listeners in a hall. Projection and preference are taken as the two broadest criteria by which listeners might meaningfully compare violins: Which violins are heard better, and which are preferred? In two separate experiments, three new violins were compared with three by Stradivari. Projection was tested both with and without orchestral accompaniment. Projection and preference were judged simultaneously by dividing listeners into two groups. Results are unambiguous. The new violins projected better than the Stradivaris, whether tested with orchestra or without; the new violins were generally preferred by the listeners; and the listeners could not reliably distinguish new from old. The single best-projecting violin was considered the loudest under the ear by players, and on average, violins that were quieter under the ear were found to project less well.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/SVNLL7FT/Fritz et al. - 2017 - Listener evaluations of new and Old Italian violin.pdf}
}

@article{fritzPlayerPreferencesNew2012,
  title = {Player Preferences among New and Old Violins},
  author = {Fritz, Claudia and Curtin, Joseph and Poitevineau, Jacques and {Morrel-Samuels}, Palmer and Tao, Fan-Chia},
  year = {2012},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {3},
  pages = {760--763},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1114999109},
  urldate = {2023-05-19},
  abstract = {Most violinists believe that instruments by Stradivari and Guarneri ``del Gesu'' are tonally superior to other violins---and to new violins in particular. Many mechanical and acoustical factors have been proposed to account for this superiority; however, the fundamental premise of tonal superiority has not yet been properly investigated. Player's judgments about a Stradivari's sound may be biased by the violin's extraordinary monetary value and historical importance, but no studies designed to preclude such biasing factors have yet been published. We asked 21 experienced violinists to compare violins by Stradivari and Guarneri del Gesu with high-quality new instruments. The resulting preferences were based on the violinists' individual experiences of playing the instruments under double-blind conditions in a room with relatively dry acoustics. We found that (               i               ) the most-preferred violin was new; (               ii               ) the least-preferred was by Stradivari; (               iii               ) there was scant correlation between an instrument's age and monetary value and its perceived quality; and (               iv               ) most players seemed unable to tell whether their most-preferred instrument was new or old. These results present a striking challenge to conventional wisdom. Differences in taste among individual players, along with differences in playing qualities among individual instruments, appear more important than any general differences between new and old violins. Rather than searching for the ``secret'' of Stradivari, future research might best focused on how violinists evaluate instruments, on which specific playing qualities are most important to them, and on how these qualities relate to measurable attributes of the instruments, whether old or new.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/PAMAN5MN/Fritz et al. - 2012 - Player preferences among new and old violins.pdf}
}

@article{fritzSoloistEvaluationsSix2014,
  title = {Soloist Evaluations of Six {{Old Italian}} and Six New Violins},
  author = {Fritz, Claudia and Curtin, Joseph and Poitevineau, Jacques and Borsarello, Hugues and Wollman, Indiana and Tao, Fan-Chia and Ghasarossian, Thierry},
  year = {2014},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {20},
  pages = {7224--7229},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1323367111},
  urldate = {2023-05-19},
  abstract = {Many researchers have sought explanations for the purported tonal superiority of Old Italian violins by investigating varnish and wood properties, plate tuning systems, and the spectral balance of the radiated sound. Nevertheless, the fundamental premise of tonal superiority has been investigated scientifically only once very recently, and results showed a general preference for new violins, and that players were unable to reliably distinguish new violins from old. The study was however relatively small in terms of the number of violins tested (six), the time allotted to each player (an hour), and the size of the test space (a hotel room). In this study 10 renowned soloists each blind-tested six Old Italian violins (including five by Stradivari) and six new during two 1h15 sessions -- the first in a rehearsal room, the second in a 300-seat concert hall. When asked to choose a violin to replace their own for a hypothetical concert tour, six of the ten soloists chose a new instrument. A single new violin was easily the most-preferred of the 12. On average, soloists rated their favorite new violins more highly than their favorite old for playability, articulation, and projection, and at least equal to old in terms of timbre. Soloists failed to distinguish new from old at better than chance levels. These results confirm and extend those of the earlier study, and present a striking challenge to nearcanonical beliefs about Old Italian violins.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/NF585B4I/Fritz et al. - 2014 - Soloist evaluations of six Old Italian and six new.pdf}
}

@inproceedings{gabrielssonAnalysisLongtimeaveragespectraTwentytwo2007,
  title = {An Analysis of Long-Time-Average-Spectra of Twentytwo Quality-Rated Violins},
  author = {Gabrielsson, A. and Jansson},
  year = {2007},
  urldate = {2024-07-15},
  abstract = {LongTime-Average-Spectra (L TAS:es) were recorded of 22 qualityrated violins. The LTAS:es were analyzed by four different methods: weight functions, factor analysis (FA), multidimensional scaling (MDS), and separate correlation analysis. The average difference between the instruments rated highest and lowest was t r ied a s a function weighting tonal quality. This weight function explained 64 70 of the variance of the tonal quality-ratings. Factor analysis and multidimensional scaling in five factor s/dimensions gave approximately the same solutions. The solutions accounted for 74 70 and 44 ' \$0 respec t ive ly of the variance of the LTAS:es and for 74 70 and 69 70 respectively of the variance of the tonal quality-ratings. The variations in certain res t r ic ted frequency regions selected by correlation analysis accounted for 7 1-84 70 of the variance in the tonal quality-ratings. The different methods imply that "strong" f r e quency components a r e favorable in a low frequency region and in a middle high frequency region, while "weak" frequency components a r e favorable in a high frequency region and in a l imited middle frequency region. The resu l t s seem reliable, a t l eas t for the selected instruments.},
  file = {/home/hugo/Zotero/storage/ZV7QB7FY/Gabrielsson and Jansson - 2007 - An analysis of long-time-average-spectra of twenty.pdf}
}

@article{gonzalezMachineLearningApproach,
  title = {A Machine Learning Approach to Violin Timbre Quality Classification},
  author = {Gonz{\'a}lez, Pedro Llad{\'o}},
  langid = {english},
  file = {/home/hugo/Zotero/storage/IKR5E9E2/González - A machine learning approach to violin timbre quali.pdf}
}

@article{greyMultidimensionalPerceptualScaling1977,
  title = {Multidimensional Perceptual Scaling of Musical Timbres},
  author = {Grey, John M.},
  year = {1977},
  month = may,
  journal = {The Journal of the Acoustical Society of America},
  volume = {61},
  number = {5},
  pages = {1270--1277},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.381428},
  urldate = {2023-10-25},
  abstract = {Two experiments were performed to evaluate the perceptual relationships between 16 music instrument tones. The stimuli were computer synthesized based upon an analysis of actual instrument tones, and they were perceptually equalized for loudness, pitch, and duration. Experiment 1 evaluated the tones with respect to perceptual similarities, and the results were treated with multidimensional scaling techniques and hierarchic clustering analysis. A three-dimensional scaling solution, well matching the clustering analysis, was found to be interpretable in terms of (1) the spectral\hphantom{,}energy\hphantom{,}distribution; (2) the presence of synchronicity in the transients of the higher harmonics, along with the closely related amount of spectral\hphantom{,}fluctuation within the the tone through time; and (3) the presence of low-amplitude, high-frequency\hphantom{,}energy in the initial attack segment; an alternate interpretation of the latter two dimensions viewed the cylindrical distribution of clusters of stimulus points about the spectral energy distribution, grouping on the basis of musical instrument family (with two exceptions). Experiment 2 was a learning task of a set of labels for the 16 tones. Confusions were examined in light of the similarity structure for the tones from experiment 1, and one of the family-grouping exceptions was found to be reflected in the difficulty of learning the labels.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/K25Q6SM3/Grey - 1977 - Multidimensional perceptual scaling of musical tim.pdf}
}

@article{guyonIntroductionVariableFeature,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/WXCHLWYL/Guyon and Elisseeff - An Introduction to Variable and Feature Selection.pdf}
}

@article{harrisUseWindowsHarmonic1978,
  title = {On the Use of Windows for Harmonic Analysis with the Discrete {{Fourier}} Transform},
  author = {Harris, F.J.},
  year = {1978},
  journal = {Proceedings of the IEEE},
  volume = {66},
  number = {1},
  pages = {51--83},
  issn = {0018-9219},
  doi = {10.1109/PROC.1978.10837},
  urldate = {2023-12-04},
  langid = {english},
  file = {/home/hugo/Zotero/storage/HGF6NT3Y/Harris - 1978 - On the use of windows for harmonic analysis with t.pdf}
}

@article{heinzelSpectrumSpectralDensity,
  title = {Spectrum and Spectral Density Estimation by the {{Discrete Fourier}} Transform ({{DFT}}), Including a Comprehensive List of Window Functions and Some New Flat-Top Windows.},
  author = {Heinzel, G and Rudiger, A and Schilling, R},
  abstract = {This report tries to give a practical overview about the estimation of power spectra/power spectral densities using the DFT/FFT. One point that is emphasized is the relationship between estimates of power spectra and power spectral densities which is given by the effective noise bandwidth (ENBW). Included is a detailed list of common and useful window functions, among them the often neglected flat-top windows. Special highlights are a procedure to test new programs, a table of comprehensive graphs for each window and the introduction of a whole family of new flat-top windows that feature sidelobe suppression levels of up to -248 dB, as compared with -90 dB of the best flat-top windows available until now.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/QKM5DAID/Heinzel et al. - Spectrum and spectral density estimation by the Di.pdf}
}

@book{hoggIntroductionMathematicalStatistics2019,
  title = {Introduction to Mathematical Statistics},
  author = {Hogg, Robert V. and McKean, Joseph W. and Craig, Allen T.},
  year = {2019},
  edition = {Eighth edition},
  publisher = {Pearson},
  address = {Boston},
  isbn = {978-0-13-468699-8},
  langid = {english},
  lccn = {QA276 .H59 2019},
  keywords = {Mathematical statistics},
  file = {/home/hugo/Zotero/storage/764GPAJ9/Hogg et al. - 2019 - Introduction to mathematical statistics.pdf}
}

@book{iiiMathematicsDiscreteFourier2007,
  title = {Mathematics of the {{Discrete Fourier Transform}} ({{DFT}}): With {{Audio Applications}} ---- {{Second Edition}}},
  shorttitle = {Mathematics of the {{Discrete Fourier Transform}} ({{DFT}})},
  author = {III, Julius O. Smith},
  year = {2007},
  month = apr,
  edition = {2nd edition},
  publisher = {W3K Publishing},
  address = {North Charleston},
  abstract = {Detailed derivation of the Discrete Fourier Transform (DFT) and its associated mathematics, including elementary audio signal processing applications and matlab programming examples.},
  isbn = {978-0-9745607-4-8},
  langid = {english},
  file = {/home/hugo/Zotero/storage/RFHFU53M/Mathematics of the Discrete Fourier Transform.pdf;/home/hugo/Zotero/storage/E677AK3W/mdft.html}
}

@misc{InvertibilityOverlapaddProcessing,
  title = {Invertibility of Overlap-Add Processing},
  urldate = {2023-11-28},
  howpublished = {https://gauss256.github.io/blog/cola.html}
}

@article{janAcousticalCorrelatesMain,
  title = {Acoustical Correlates of the Main Features of Violin Timbre Perception},
  author = {Jan, Stepanek and Zdenek, Otcenasek},
  abstract = {An experimental approach to the study of timbre is described. Series of listening tests were performed separately with recordings of violin tones B3, F\#4, C5, G5 and D6, played on various quality violins. Two main approaches to the discovering of acoustical correlates of most important perceptual features are described. The first approach is directly focused on interpretation of perceptual spaces using acoustic characteristics. The second one uses selected verbal attributes used by listeners to the description of timbre differences and tries to found their explanation using acoustic characteristics. Method of immersion of acoustic characteristic into perceptual space revealed the importance of the first harmonic, higher harmonics and spectral centre of gravity in all studied tones. The change of their relations (similarity, contradiction, or independence) with changing pitch is also discussed. Mutual relations of verbal attributes sharp, dark, clear and narrow in sounds of five studied tones are discovered; acoustical correlates of the main attributes sharp and narrow are found, compared and discussed. Moreover acoustical correlates of attribute rustle in high violin tones are mentioned. Findings of both approaches to the study of timbre are compared and discussed.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/APDQEVIU/Jan and Zdenek - Acoustical correlates of the main features of viol.pdf}
}

@inproceedings{janssonLongtimeaveragespectraAppliedAnalysis2007a,
  title = {Long-Time-Average-Spectra Applied to Analysis of Music},
  author = {Jansson},
  year = {2007},
  urldate = {2024-07-15},
  abstract = {Semantic Scholar extracted view of "Long-time-average-spectra applied to analysis of music" by Jansson},
  file = {/home/hugo/Zotero/storage/PQCQ8MHP/Jansson - 2007 - Long-time-average-spectra applied to analysis of m.pdf}
}

@book{johnsonFeatureEngineeringSelection,
  title = {Feature {{Engineering}} and {{Selection}}: {{A Practical Approach}} for {{Predictive Models}}},
  shorttitle = {Feature {{Engineering}} and {{Selection}}},
  author = {Johnson, Max Kuhn {and} Kjell},
  urldate = {2023-11-13},
  abstract = {A primary goal of predictive modeling is to find a reliable and effective predic- tive relationship between an available set of features and an outcome. This book provides an extensive set of techniques for uncovering effective representations of the features for modeling the outcome and for finding an optimal subset of features to improve a model's predictive performance.},
  file = {/home/hugo/Zotero/storage/VRH9Z2T7/www.feat.engineering.html}
}

@misc{lAnswerWhatShould2016,
  title = {Answer to "{{What}} Should Be the Correct Scaling for {{PSD}} Calculation Using \${\textbackslash}tt Fft\$"},
  author = {L, Matt},
  year = {2016},
  month = jul,
  journal = {Signal Processing Stack Exchange},
  urldate = {2023-12-04}
}

@article{larsenINTRODUCTIONMATHEMATICALSTATISTICS,
  title = {{{AN INTRODUCTION TO MATHEMATICAL STATISTICS AND ITS APPLICATIONS}}},
  author = {Larsen, Richard J and Marx, Morris L},
  langid = {english},
  file = {/home/hugo/Zotero/storage/MFYQTANU/Larsen and Marx - AN INTRODUCTION TO MATHEMATICAL STATISTICS AND ITS.pdf}
}

@misc{LearnFluCoMa,
  title = {Learn {{FluCoMa}}},
  urldate = {2023-11-09},
  howpublished = {https://learn.flucoma.org/reference/spectralshape/},
  file = {/home/hugo/Zotero/storage/HKHF4HPJ/spectralshape.html}
}

@misc{liMERTAcousticMusic2024,
  title = {{{MERT}}: {{Acoustic Music Understanding Model}} with {{Large-Scale Self-supervised Training}}},
  shorttitle = {{{MERT}}},
  author = {Li, Yizhi and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Chen, Xingran and Yin, Hanzhi and Xiao, Chenghao and Lin, Chenghua and Ragni, Anton and Benetos, Emmanouil and Gyenge, Norbert and Dannenberg, Roger and Liu, Ruibo and Chen, Wenhu and Xia, Gus and Shi, Yemin and Huang, Wenhao and Wang, Zili and Guo, Yike and Fu, Jie},
  year = {2024},
  month = apr,
  number = {arXiv:2306.00107},
  eprint = {2306.00107},
  primaryclass = {cs, eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.00107},
  urldate = {2024-05-02},
  abstract = {Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is partially due to the distinctive challenges associated with modelling musical knowledge, particularly tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified an effective combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantisation - Variational AutoEncoder (RVQ-VAE) and a musical teacher based on the Constant-Q Transform (CQT). Furthermore, we explore a wide range of settings to overcome the instability in acoustic language model pre-training, which allows our designed paradigm to scale from 95M to 330M parameters. Experimental results indicate that our model can generalise and perform well on 14 music understanding tasks and attain state-of-the-art (SOTA) overall scores.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/hugo/Zotero/storage/XTVNJ4K5/Li et al. - 2024 - MERT Acoustic Music Understanding Model with Larg.pdf;/home/hugo/Zotero/storage/66GNWYNS/2306.html}
}

@inproceedings{lukasikAMATIMultimediaDatabase2003,
  title = {{{AMATI}} - {{Multimedia Database}} of {{Violin Sounds}}},
  author = {Lukasik, Ewa},
  year = {2003},
  month = jan
}

@article{lukasikLongTermCepstral2009,
  title = {Long {{Term Cepstral Coefficients}} for Violin Identification},
  author = {Lukasik, Ewa},
  year = {2009},
  abstract = {Cepstral coefficients in mel scale proved to be efficient features for speaker and musical instrument recognition. In this paper Long Term Cepstral Coefficients -- LTCCs -- of solo musical phrases are used as features for identification of individual violins. LTCC represents the envelope of LTAS -- Long Term Average Spectrum in linear scale useful to characterize the subtleties' of violin sound in frequency domain. Results of the classification of 60 instruments are presented and discussed. It was shown, that if the experts' knowledge is applied to analyze violin sound, the results may be promising.},
  langid = {english},
  keywords = {Identification},
  file = {/home/hugo/Zotero/storage/VJCK4CJV/Lukasik - 2009 - Long Term Cepstral Coefficients for violin identif.pdf}
}

@article{lukasikLongTermCepstral2010b,
  title = {Long {{Term Cepstral Coefficients}} for {{Violin Identification}}},
  author = {Lukasik, E.},
  year = {2010},
  month = may,
  journal = {Journal of The Audio Engineering Society},
  urldate = {2024-04-24},
  abstract = {Cepstral coefficients in mel scale proved to be efficient features for speaker and musical instrument recognition. In this paper Long Term Cepstral Coefficients  LTCCs  of solo musical phrases are used as features for identification of individual violins. LTCC represents the envelope of LTAS  Long Term Average Spectrum in linear scale useful to characterize the subtleties of violin sound in frequency domain. Results of the classification of 60 instruments are presented and discussed. It was shown, that if the experts knowledge is applied to analyze violin sound, the results may be promising.},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/RI2R6L4S/Lukasik - 2010 - Long Term Cepstral Coefficients for Violin Identif.pdf}
}

@article{magalhaesIracemaPythonLibrary2020,
  title = {Iracema: A {{Python}} Library for Audio Content Analysis},
  shorttitle = {Iracema},
  author = {Magalhaes, Tairone and Barros, Felippe and Loureiro, Mauricio},
  year = {2020},
  month = dec,
  journal = {Revista de Inform{\'a}tica Te{\'o}rica e Aplicada},
  volume = {27},
  pages = {127--138},
  doi = {10.22456/2175-2745.107202},
  abstract = {Iracema is a Python library that aims to provide models for the extraction of meaningful informationfrom recordings of monophonic pieces of music, for purposes of research in music performance. With this objective in mind, we propose an architecture that will provide to users an abstraction level that simplifies the manipulation of different kinds of time series, as well as the extraction of segments from them. In this paper we: (1) introduce some key concepts at the core of the proposed architecture; (2) describe the current functionalities of the package; (3) give some examples of the application programming interface; and (4) give some brief examples of audio analysis using the system.},
  file = {/home/hugo/Zotero/storage/96APEH5H/Magalhaes et al. - 2020 - Iracema a Python library for audio content analys.pdf}
}

@article{martinMusicalInstrumentIdentification1998,
  title = {Musical Instrument Identification: {{A}} Pattern-Recognition Approach},
  shorttitle = {Musical Instrument Identification},
  author = {Martin, Keith D. and Kim, Youngmoo E.},
  year = {1998},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {104},
  number = {3\_Supplement},
  pages = {1768--1768},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.424083},
  urldate = {2024-05-07},
  abstract = {A statistical pattern-recognition technique was applied to the classification of musical instrument tones within a taxonomic hierarchy. Perceptually salient acoustic features---related to the physical properties of source excitation and resonance structure---were measured from the output of an auditory model (the log-lag correlogram) for 1023 isolated tones over the full pitch ranges of 15 orchestral instruments. The data set included examples from the string (bowed and plucked), woodwind (single, double, and air reed), and brass families. Using 70\%/30\% splits between training and test data, maximum a\hphantom{,}posteriori classifiers were constructed based on Gaussian models arrived at through Fisher multiple-discriminant analysis. The classifiers distinguished transient from continuant tones with approximately 99\% correct performance. Instrument families were identified with approximately 90\% performance, and individual instruments were identified with an overall success rate of approximately 70\%. These preliminary analyses compare favorably with human performance on the same task and demonstrate the utility of the hierarchical approach to classification.},
  langid = {english}
}

@article{moesMecaniqueMilieuxContinus,
  title = {{M{\'e}canique des milieux continus}},
  author = {Mo{\"e}s, Nicolas},
  langid = {french},
  file = {/home/hugo/Zotero/storage/QPCEK5MM/Moës - Mécanique des milieux continus.pdf}
}

@article{MomentMathematics2023,
  title = {Moment (Mathematics)},
  year = {2023},
  month = jun,
  journal = {Wikipedia},
  urldate = {2023-11-09},
  abstract = {In mathematics, the moments of a function are certain quantitative measures related to the shape of the function's graph. If the function represents mass density, then the zeroth moment is the total mass, the first moment (normalized by total mass) is the center of mass, and the second moment is the moment of inertia. If the function is a probability distribution, then the first moment is the expected value, the second central moment is the variance, the third standardized moment is the skewness, and the fourth standardized moment is the kurtosis. The mathematical concept is closely related to the concept of moment in physics. For a distribution of mass or probability on a bounded interval, the collection of all the moments (of all orders, from 0 to {$\infty$}) uniquely determines the distribution (Hausdorff moment problem).  The same is not true on unbounded intervals (Hamburger moment problem). In the mid-nineteenth century, Pafnuty Chebyshev became the first person to think systematically in terms of the moments of random variables.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1160595776},
  file = {/home/hugo/Zotero/storage/8MZ4ZQXS/Moment_(mathematics).html}
}

@book{mooreHearing1995,
  title = {Hearing},
  editor = {Moore, Brian C. J.},
  year = {1995},
  month = sep,
  edition = {1st edition},
  publisher = {Academic Press},
  address = {San Diego},
  abstract = {Hearing is a comprehensive, authoritative reference work covering both the physiological and perceptual aspects of hearing. Intended for researchers and advanced students in the field of hearing, it reviews major areas of research in addition to new discoveries, including active mechanisms in the cochlea, across-channel processes in auditory masking, and perceptual grouping processes.Covers both physiological and perceptual aspects of hearingAuthoritative reviews by experts in the fieldComprehensive up-to-date coverageAn integrated work with extensive cross-references between chapters},
  isbn = {978-0-12-505626-7},
  langid = {english}
}

@inproceedings{moralLongtimeaveragespectraScalesSpectra2007,
  title = {Long-Time-Average-Spectra of Scales and Spectra of Single Tones from a Violin},
  author = {Moral, A.},
  year = {2007},
  urldate = {2024-07-15},
  abstract = {Long-Time-Average-Spectra, LTAS:es, have proved to give representative records of violins. The fulltime scales recorded in a reverberation chamber have, however, not been well suited for listening tests. Therefore in this investigation the recordings were made in an anechoic chamber and the effects on the LTAS by reducing the number of tones played were tried. Furthermore, the relations were investigated between Single-Tone -Spectra, STS :es, and LTAS:es. The investigations show that a representative LTAS of a violin can be obtained from every third tone on the two middle strings. Furthermore, i t shows that the spectrum level of all strings a r e approximately equal to 12 Bark and thereafter it drops 4 dB from a string to the next lower and that the high frequency limit of each string drops one Bark from one string to the next lower string. The levels of the STS:es fall in general within f 5 dB of the LTAS of the same string.}
}

@article{muckenhirnLongTermSpectralStatistics2017,
  title = {Long-{{Term Spectral Statistics}} for {{Voice Presentation Attack Detection}}},
  author = {Muckenhirn, Hannah and Korshunov, Pavel and {Magimai-Doss}, Mathew and Marcel, Sebastien},
  year = {2017},
  month = nov,
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {25},
  number = {11},
  pages = {2098--2111},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2017.2743340},
  urldate = {2024-08-30},
  abstract = {Automatic speaker verification systems can be spoofed through recorded, synthetic or voice converted speech of target speakers. To make these systems practically viable, the detection of such attacks, referred to as presentation attacks, is of paramount interest. In that direction, this paper investigates two aspects: (a) a novel approach to detect presentation attacks where, unlike conventional approaches, no speech signal modeling related assumptions are made, rather the attacks are detected by computing first order and second order spectral statistics and feeding them to a classifier, and (b) generalization of the presentation attack detection systems across databases. Our investigations on ASVspoof 2015 challenge database and AVspoof database show that, when compared to the approaches based on conventional short-term spectral features, the proposed approach with a linear discriminative classifier yields a better system, irrespective of whether the spoofed signal is replayed to the microphone or is directly injected into the system software process. Cross-database investigations show that neither the short-term spectral processing based approaches nor the proposed approach yield systems which are able to generalize across databases or methods of attack. Thus, revealing the difficulty of the problem and the need for further resources and research.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/home/hugo/Zotero/storage/5I6J7768/Muckenhirn et al. - 2017 - Long-Term Spectral Statistics for Voice Presentati.pdf}
}

@article{navarroLearningStatistics,
  title = {Learning {{Statistics}} with {{R}}},
  author = {Navarro, Daniel},
  langid = {english},
  file = {/home/hugo/Zotero/storage/B54P48K6/Navarro - Learning Statistics with R.pdf}
}

@article{osorioJudgementRankingLiving,
  title = {Judgement and {{Ranking}}: {{Living}} with {{Hidden Bias}}},
  author = {Osorio, Antonio},
  abstract = {The complexity and subjectivity of the judgement task conceals the existence of biases that undermines the quality of the process. This paper presents a weighted aggregation function that attempts to reduce the influence of biased judgements on the final score. We also discuss a set of desirable properties. The proposed weighted aggregation function is able to correct the ``nationalism bias''found by Emerson et al. (2009) in the 2000 Olympic Games diving competition and suggest the possibility of a ``reputation bias''. Our results can be applied to judgement sports and other activities that require the aggregation of several personal evaluations.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/7SMCSQQ4/Osorio - Judgement and Ranking Living with Hidden Bias.pdf}
}

@article{peetersLargeSetAudio2004,
  title = {A Large Set of Audio Features for Sound Description (Similarity and Classification) in the {{CUIDADO}} Project},
  author = {Peeters, Geoffroy},
  year = {2004},
  month = jan,
  file = {/home/hugo/Zotero/storage/8ZTPG5ZK/Peeters_2003_cuidadoaudiofeatures.pdf}
}

@article{peetersTimbreToolboxExtracting2011,
  title = {The {{Timbre Toolbox}}: {{Extracting}} Audio Descriptors from Musical Signals},
  shorttitle = {The {{Timbre Toolbox}}},
  author = {Peeters, Geoffroy and Giordano, Bruno L. and Susini, Patrick and Misdariis, Nicolas and McAdams, Stephen},
  year = {2011},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {130},
  number = {5},
  pages = {2902--2916},
  issn = {0001-4966},
  doi = {10.1121/1.3642604},
  urldate = {2023-10-31},
  abstract = {The analysis of musical signals to extract audio descriptors that can potentially characterize their timbre has been disparate and often too focused on a particular small set of sounds. The Timbre Toolbox provides a comprehensive set of descriptors that can be useful in perceptual research, as well as in music information retrieval and machine-learning approaches to content-based retrieval in large sound databases. Sound events are first analyzed in terms of various input representations (short-term Fourier transform, harmonic sinusoidal components, an auditory model based on the equivalent rectangular bandwidth concept, the energy envelope). A large number of audio descriptors are then derived from each of these representations to capture temporal, spectral, spectrotemporal, and energetic properties of the sound events. Some descriptors are global, providing a single value for the whole sound event, whereas others are time-varying. Robust descriptive statistics are used to characterize the time-varying descriptors. To examine the information redundancy across audio descriptors, correlational analysis followed by hierarchical clustering is performed. This analysis suggests ten classes of relatively independent audio descriptors, showing that the Timbre Toolbox is a multidimensional instrument for the measurement of the acoustical structure of complex sound signals.},
  file = {/home/hugo/Zotero/storage/ZILC8WBB/Peeters et al. - 2011 - The Timbre Toolbox Extracting audio descriptors f.pdf;/home/hugo/Zotero/storage/BP3II4RJ/The-Timbre-Toolbox-Extracting-audio-descriptors.html}
}

@inproceedings{petiotCONTRIBUTIONMACHINELEARNING2023,
  title = {{{CONTRIBUTION OF MACHINE LEARNING AND PHYSICS-BASED SOUND SIMULATIONS FOR THE CHARACTERIZATION OF BRASS INSTRUMENTS}}},
  booktitle = {Forum {{Acusticum}} 2023},
  author = {Petiot, Jean-Fran{\c c}ois and Roatta, Misael and Fr{\'e}our, Vincent and Arimoto, Keita},
  year = {2023},
  month = sep,
  urldate = {2024-01-11},
  abstract = {Sound simulations by physical modelling are interesting to transcribe the physics underlying the functioning of a musical instrument. These simulations make it possible to listen to a virtual instrument with a mode of operation representative of the musician-instrument interaction. The work consists of studying the contribution of machine learning (ML) methods in the understanding of the relationships between the shape of a trumpet and the sound simulated. The physical model used is based on an acoustical modeling of the resonator, a mechanical model of the excitator, and an aeroelastic coupling between the excitator and the resonator. From different samples of the input impedance of the resonator, time domain simulations are generated to constitute a training set of sounds. Supervised learning is next trained to the data, with the impedance as input and sound descriptors as outputs, using classical ML methods (neural networks). The ML model is finally used to optimize the sound descriptors levels, according to the input impedance. To illustrate the approach, different "targets" for the sound features are considered (brightness, intonation), and a validation is conducted with the simulations. The approach is a first stage toward a "customization" of an instrument according to different perceptual dimensions.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/EXN9Q4V8/Petiot et al. - 2023 - CONTRIBUTION OF MACHINE LEARNING AND PHYSICS-BASED.pdf}
}

@misc{PhilippeLalitteExpressivite,
  title = {Philippe {{Lalitte}} - {{L}}'expressivit{\'e} de La Performance Des {{Dix}} Pi{\`e}ces Pour Quintette {\`a} Vent de {{Ligeti}} ({{Musim{\'e}diane}} 9)},
  urldate = {2023-05-19},
  howpublished = {https://www.musimediane.com/numero9/LALITTE/},
  file = {/home/hugo/Zotero/storage/RN73KNB7/LALITTE.html}
}

@misc{pPSDScailingFactor2022,
  type = {Forum Post},
  title = {About {{PSD}} Scailing Factor},
  author = {P, Arathi},
  year = {2022},
  month = jan,
  journal = {Signal Processing Stack Exchange},
  urldate = {2023-11-28},
  file = {/home/hugo/Zotero/storage/DRUEJLR3/about-psd-scailing-factor.html}
}

@misc{PrefaceDigitalSignals,
  title = {Preface --- {{Digital Signals Theory}}},
  urldate = {2023-11-28},
  howpublished = {https://brianmcfee.net/dstbook-site/content/intro.html},
  file = {/home/hugo/Zotero/storage/7UKPSAMF/intro.html}
}

@article{ProjetRechercheDoctorale,
  title = {{Projet de recherche doctorale au sein du Collegium Musicae}},
  langid = {french},
  file = {/home/hugo/Zotero/storage/7DBR576I/Projet de recherche doctorale au sein du Collegium.pdf}
}

@book{rogersDiscriminationTestingSensory2017,
  title = {Discrimination Testing in Sensory Science: A Practical Handbook},
  shorttitle = {Discrimination Testing in Sensory Science},
  editor = {Rogers, Lauren},
  year = {2017},
  series = {Woodhead Publishing Series in Food Science, Technology and Nutrition},
  publisher = {Elsevier/Woodhead Publishing},
  address = {Duxford},
  isbn = {978-0-08-101009-9 978-0-08-101116-4},
  langid = {english},
  lccn = {QP435 .D53 2017},
  keywords = {Discrimination (Psychology),Handbooks and manuals,Handbooks manuals etc,Sensation,Sensory discrimination,Testing},
  annotation = {OCLC: on1008602402},
  file = {/home/hugo/Zotero/storage/3YRC9QQR/Rogers - 2017 - Discrimination testing in sensory science a pract.pdf}
}

@article{rougierScientificVisualizationPython,
  title = {Scientific {{Visualization}}: {{Python}} + {{Matplotlib}}},
  author = {Rougier, Nicolas P},
  langid = {english},
  file = {/home/hugo/Zotero/storage/NQZNEEKL/Rougier - Scientific Visualization Python + Matplotlib.pdf}
}

@article{rougierScientificVisualizationPythona,
  title = {Scientific {{Visualization}}: {{Python}}  {{Matplotlib}}},
  author = {Rougier, Nicolas P},
  langid = {english},
  file = {/home/hugo/Zotero/storage/NVK7RMLS/Rougier - Scientific Visualization Python  Matplotlib.pdf}
}

@article{rousselCoursMecaniqueClassique,
  title = {{Cours de m{\'e}canique classique -- femto-physique.fr}},
  author = {Roussel, Jimmy},
  langid = {french},
  file = {/home/hugo/Zotero/storage/SUU337HQ/Roussel - Cours de mécanique classique – femto-physique.fr.pdf}
}

@article{saitisSoundsMeltedChocolate2019,
  title = {Sounds like Melted Chocolate: {{How}} Musicians Conceptualize Violin Sound Richness},
  author = {Saitis, Charalampos and Fritz, Claudia and Scavone, Gary},
  year = {2019},
  abstract = {Results from a previous study on the perceptual evaluation of violins that involved playing-based semantic ratings showed that preference for a violin was strongly associated with its perceived sound richness. However, both preference and richness ratings varied widely between individual violinists, likely because musicians conceptualize the same attribute in different ways. To better understand how richness is conceptualized by violinists and how it contributes to the perceived quality of a violin, we analyzed free verbal descriptions collected during a carefully controlled playing task (involving 16 violinists) and in an online survey where no sound examples or other contextual information was present (involving 34 violinists). The analysis was based on a psycholinguistic method, whereby semantic categories are inferred from the verbal data itself through syntactic context and linguistic markers. The main sensory property related to violin sound richness was expressed through words such as full, complex, and dense versus thin and small, referring to the perceived number of partials present in the sound. Another sensory property was expressed through words such as warm, velvety, and smooth versus strident, harsh, and tinny, alluding to spectral energy distribution cues. Haptic cues were also implicated in the conceptualization of violin sound richness.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/BG5BBAX3/Saitis et al. - 2019 - Sounds like melted chocolate How musicians concep.pdf}
}

@misc{ScalingDFTMore,
  title = {Scaling of the {{DFT}} and {{Some More}} of {{Its Noteworthy Properties}}},
  journal = {Scaling of the DFT and Some More of Its Noteworthy Properties},
  urldate = {2023-11-28},
  abstract = {Supplementary Materials for the AES Tutorial on Scaling of the Discrete Fourier Transform, see the pages:},
  howpublished = {https://appliedacousticschalmers.github.io/scaling-of-the-dft/AES2020\_eBrief/},
  langid = {american},
  file = {/home/hugo/Zotero/storage/46VB8BWR/AES2020_eBrief.html}
}

@inproceedings{scheirerConstructionEvaluationRobust1997,
  title = {Construction and Evaluation of a Robust Multifeature Speech/Music Discriminator},
  booktitle = {1997 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  author = {Scheirer, E. and Slaney, M.},
  year = {1997},
  volume = {2},
  pages = {1331--1334},
  publisher = {IEEE Comput. Soc. Press},
  address = {Munich, Germany},
  doi = {10.1109/ICASSP.1997.596192},
  urldate = {2023-11-09},
  abstract = {We report on the construction of a real-time computer system capable of distinguishing speech signals from music signals over a wide range of digital audio input. We have examined 13 features intended to measure conceptually distinct properties of speech and/or music signals, and combined them in several multidimensional classification frameworks. We provide extensive data on system performance and the cross-validated training/test setup used to evaluate the system. For the datasets currently in use, the best classifier classifies with 5.8\% error on a frame-by-frame basis, and 1.4\% error when integrating long (2.4 second) segments of sound.},
  isbn = {978-0-8186-7919-3},
  langid = {english},
  file = {/home/hugo/Zotero/storage/8VKJN3QL/Scheirer and Slaney - 1997 - Construction and evaluation of a robust multifeatu.pdf}
}

@article{schollExactSignalMeasurements,
  title = {Exact {{Signal Measurements}} Using {{FFT Analysis}}},
  author = {Scholl, Stefan},
  langid = {english},
  file = {/home/hugo/Zotero/storage/8YBHXERQ/Scholl - Exact Signal Measurements using FFT Analysis.pdf}
}

@article{schoonderwaldtViolinistSoundPalette2009,
  title = {The {{Violinist}}'s {{Sound Palette}}: {{Spectral Centroid}}, {{Pitch Flattening}} and {{Anomalous Low Frequencies}}},
  shorttitle = {The {{Violinist}}'s {{Sound Palette}}},
  author = {Schoonderwaldt, Erwin},
  year = {2009},
  month = sep,
  journal = {Acta Acustica united with Acustica},
  volume = {95},
  number = {5},
  pages = {901--914},
  issn = {16101928},
  doi = {10.3813/AAA.918221},
  urldate = {2023-10-17},
  langid = {english},
  file = {/home/hugo/Zotero/storage/IM6PU8GD/Schoonderwaldt - 2009 - The Violinist's Sound Palette Spectral Centroid, .pdf}
}

@inproceedings{setragnoFeaturebasedCharacterizationViolin2017,
  title = {Feature-Based Characterization of Violin Timbre},
  booktitle = {2017 25th {{European Signal Processing Conference}} ({{EUSIPCO}})},
  author = {Setragno, Francesco and Zanoni, Massimiliano and Sarti, Augusto and Antonacci, Fabio},
  year = {2017},
  month = aug,
  pages = {1853--1857},
  publisher = {IEEE},
  address = {Kos, Greece},
  doi = {10.23919/EUSIPCO.2017.8081530},
  urldate = {2023-10-25},
  abstract = {Timbral quality of historical violins has been discussed for years. In this paper, we show that it is possible to characterize it from an objective, low-level features perspective. Feature selection algorithms are used to select the features that most characterize historical and contemporary violins. The feature representation of violins is then reduced by means of the T-SNE method. In the low-dimensional space which is obtained, historical violins tend to group together.},
  isbn = {978-0-9928626-7-1},
  langid = {english},
  file = {/home/hugo/Zotero/storage/AFB4CYKB/Setragno et al. - 2017 - Feature-based characterization of violin timbre.pdf}
}

@inproceedings{setragnoFeatureBasedTimbralCharacterization2017,
  title = {Feature-{{Based Timbral Characterization}} of {{Historical}} and {{Modern Violins}}},
  author = {Setragno, F. and Zanoni, M. and Antonacci, F. and Sarti, A.},
  year = {2017},
  urldate = {2024-04-24},
  abstract = {Violin timbre is a very complex case of study. The sound properties that distinguish an historical violin from a modern one are still not clear. The purpose of this study is to understand what are these properties, by means of feature-based analysis. We extract audio features related to timbre and we exploit feature selection techniques in order to investigate what are the most characterizing ones. We compare different feature selection algorithms and we illustrate how we applied their outcome to a classification task with historical and modern instruments. Results show that the classification performance improves when using the selected features.},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/DAV99MI7/Setragno et al. - 2017 - Feature-Based Timbral Characterization of Historic.pdf}
}

@book{shaoMathematicalStatistics2003,
  title = {Mathematical {{Statistics}}},
  author = {Shao, Jun},
  editor = {Casella, G. and Fienberg, S. and Olkin, I.},
  year = {2003},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/b97553},
  urldate = {2023-12-18},
  isbn = {978-0-387-95382-3 978-0-387-21718-5},
  keywords = {likelihood,Markov chain,Mathematica,mathematical statistics,Mathematical Statistics,probability,probability theory,statistical theory,Statistical Theory,statistics},
  file = {/home/hugo/Zotero/storage/HI3FTSAH/Shao - 2003 - Mathematical Statistics.pdf}
}

@book{siedenburgTimbreAcousticsPerception2019,
  title = {Timbre: {{Acoustics}}, {{Perception}}, and {{Cognition}}},
  shorttitle = {Timbre},
  editor = {Siedenburg, Kai and Saitis, Charalampos and McAdams, Stephen and Popper, Arthur N. and Fay, Richard R.},
  year = {2019},
  series = {Springer {{Handbook}} of {{Auditory Research}}},
  volume = {69},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-14832-4},
  urldate = {2023-10-25},
  isbn = {978-3-030-14831-7 978-3-030-14832-4},
  langid = {english},
  keywords = {acoustics,artificial intelligence,cochlear implants,computational acoustic models,duration,hearing,human voice,loudness,modulation,perception,pitch,sound design,speech processing,voice identity recognition},
  file = {/home/hugo/Zotero/storage/MJZL3EBJ/Siedenburg et al. - 2019 - Timbre Acoustics, Perception, and Cognition.pdf}
}

@article{Skewness2023,
  title = {Skewness},
  year = {2023},
  month = nov,
  journal = {Wikipedia},
  urldate = {2023-11-09},
  abstract = {In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive, zero, negative, or undefined. For a unimodal distribution, negative skew commonly indicates that the tail is on the left side of the distribution, and positive skew indicates that the tail is on the right. In cases where one tail is long but the other tail is fat, skewness does not obey a simple rule. For example, a zero value means that the tails on both sides of the mean balance out overall; this is the case for a symmetric distribution, but can also be true for an asymmetric distribution where one tail is long and thin, and the other is short but fat.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1184083610},
  file = {/home/hugo/Zotero/storage/HCQH7GMA/Skewness.html}
}

@misc{SpectralDescriptorsMATLAB,
  title = {Spectral {{Descriptors}} - {{MATLAB}} \& {{Simulink}} - {{MathWorks France}}},
  urldate = {2023-11-09},
  howpublished = {https://fr.mathworks.com/help/audio/ug/spectral-descriptors.html\#SpectralDescriptorsExample-1},
  file = {/home/hugo/Zotero/storage/HN5J6R6P/spectral-descriptors.html}
}

@book{stanczykFeatureSelectionData2015,
  title = {Feature {{Selection}} for {{Data}} and {{Pattern Recognition}}},
  author = {Sta{\'n}czyk},
  year = {2015},
  month = jan,
  edition = {2015th edition},
  publisher = {Springer},
  address = {Heidelberg Berlin},
  abstract = {This research book provides the reader with a selection of high-quality texts dedicated to current progress, new developments and research trends in feature selection for data and pattern recognition. Even though it has been the subject of interest for some time, feature selection remains one of actively pursued avenues of investigations due to its importance and bearing upon other problems and tasks. This volume points to a number of advances topically subdivided into four parts: estimation of importance of characteristic features, their relevance, dependencies, weighting and ranking; rough set approach to attribute reduction with focus on relative reducts; construction of rules and their evaluation; and data- and domain-oriented methodologies.},
  isbn = {978-3-662-45619-4},
  langid = {english},
  file = {/home/hugo/Zotero/storage/V7UJCZB8/Stańczyk - 2015 - Feature Selection for Data and Pattern Recognition.pdf}
}

@article{StandardizedMoment2023,
  title = {Standardized Moment},
  year = {2023},
  month = jan,
  journal = {Wikipedia},
  urldate = {2023-11-09},
  abstract = {In probability theory and statistics, a standardized moment of a probability distribution is a moment (often a higher degree central moment) that is normalized, typically by a power of the standard deviation, rendering the moment scale invariant. The shape of different probability distributions can be compared using standardized moments.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1131377470},
  file = {/home/hugo/Zotero/storage/LNPK2J3X/Standardized_moment.html}
}

@article{stepanekMusicalSoundTimbre2006,
  title = {Musical {{Sound Timbre}}: {{Verbal Description}} and {{Dimensions}}},
  author = {Stepanek, Jan},
  year = {2006},
  abstract = {Two approaches to the study of musical sound timbre are described and documented by psychoacoustic experiment examples. The classical bottom-up approach is demonstrated on the study of contexts of violin sounds and pipe organ sounds. Verbal attributes collected during listening tests were used for the interpretation and comparison of resulted perceptual spaces of sounds.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/4M967ET5/Stepanek - 2006 - Musical Sound Timbre Verbal Description and Dimen.pdf}
}

@book{taylorClassicalMechanics2005,
  title = {Classical Mechanics},
  author = {Taylor, John R.},
  year = {2005},
  edition = {Nachdr.},
  publisher = {University Science Books},
  address = {Sausalito, Calif},
  isbn = {978-1-891389-22-1},
  langid = {english},
  file = {/home/hugo/Zotero/storage/834T7DGS/John R. Taylor - Classical Mechanics-University Science Books (2005).djvu}
}

@article{turckheimNovelImpulseResponse2010,
  title = {Novel {{Impulse Response Measurement Method}} for {{Stringed Instruments}}},
  author = {T{\"u}rckheim, Friedrich and Smit, Thorsten and Hahne, Carolin and Mores, Robert},
  year = {2010},
  abstract = {This paper introduces a measurement technique which delivers highly reproducible impulse responses of stringed instruments. The method bases on exciting the dampened strings at the bowing or plucking position by means of a thin copper wire which is pulled until it breaks. Taking into account the longitudinal and torsional movements of a bridge caused by string deflection, such stimulus of an instrument is close to the musical application. On the basis of the string-wire geometry, measurement setups can be exactly specified and individually adjusted, allowing for highly accurate repetition in comparative studies. The setup, including a fully automated exciting apparatus as well as a 'silent' quadrochord, is described in detail. Furthermore, the method is compared with the commonly used impact hammer method. Finally, an application in the context of a research project on violin sound quality is briefly described, where the technique is used to measure binaural impulse responses of violins.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/K4VRFSIJ/Türckheim et al. - 2010 - Novel Impulse Response Measurement Method for Stri.pdf}
}

@article{turckheimSemiVirtualViolinPerception,
  title = {The {{Semi-Virtual Violin}} -- {{A Perception Tool}}},
  author = {T{\"u}rckheim, Friedrich and Smit, Thorsten and Mores, Robert},
  abstract = {In this paper, a semi-virtual violin is presented which has been developed in the context of a research project on desirable violin sound properties. The method used here focuses on musicians' perception of spectral components rather than on physical modeling properties. A silent violin which has been designed with particular emphasis on authentic haptic and visual properties is used as interface between musician and virtual body. Binaural transfer functions of real violins measured at the violinist's hearing position serve as initial sound references for further spectral modifications. A filtering software enables highly-detailed modifications in the frequency domain, changing individual resonances or resonance areas while leaving other resonances unaffected. Implementation on an external signal processor provides for real-time sound processing. An application example demonstrates the tools capability: The presented tool can be used, inter alia, to manipulate the vowel quality in violin tones by modifying specific formant properties.},
  file = {/home/hugo/Zotero/storage/8WTMS9EA/Türckheim et al. - The Semi-Virtual Violin – A Perception Tool.pdf}
}

@article{Valeur2023,
  title = {{Valeur p}},
  year = {2023},
  month = feb,
  journal = {Wikip{\'e}dia},
  urldate = {2023-11-10},
  abstract = {Dans un test statistique, la valeur-p (en anglais p-value pour probability value), parfois aussi appel{\'e}e p-valeur, est la probabilit{\'e} pour un mod{\`e}le statistique donn{\'e} sous l'hypoth{\`e}se nulle d'obtenir une valeur au moins aussi extr{\^e}me que celle observ{\'e}e. L'usage de la valeur-p est courant dans de nombreux domaines de recherche comme la physique, la psychologie, l'{\'e}conomie et les sciences de la vie.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {french},
  annotation = {Page Version ID: 201421523},
  file = {/home/hugo/Zotero/storage/UDR8G3KP/Valeur_p.html}
}

@misc{VincentPerreault0TimbretoolboxToolbox,
  title = {{{VincentPerreault0}}/Timbretoolbox: {{A}} Toolbox for Extracting Audio Descriptors in {{MATLAB}}.},
  urldate = {2023-12-14},
  howpublished = {https://github.com/VincentPerreault0/timbretoolbox/tree/master},
  file = {/home/hugo/Zotero/storage/GUHXEFMX/master.html}
}

@article{wangIndividualViolinRecognition2020,
  title = {Individual {{Violin Recognition Method Combining Tonal}} and {{Nontonal Features}}},
  author = {Wang, Qi and Bao, Changchun},
  year = {2020},
  month = jun,
  journal = {Electronics},
  volume = {9},
  number = {6},
  pages = {950},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics9060950},
  urldate = {2023-10-16},
  abstract = {Individual recognition among instruments of the same type is a challenging problem and it has been rarely investigated. In this study, the individual recognition of violins is explored. Based on the source--filter model, the spectrum can be divided into tonal content and nontonal content, which reflects the timbre from complementary aspects. The tonal/nontonal gammatone frequency cepstral coefficients (GFCC) are combined to describe the corresponding spectrum contents in this study. In the recognition system, Gaussian mixture models--universal background model (GMM--UBM) is employed to parameterize the distribution of the combined features. In order to evaluate the recognition task of violin individuals, a solo dataset including 86 violins is developed in this study. Compared with other features, the combined features show a better performance in both individual violin recognition and violin grade classification. Experimental results also show the GMM--UBM outperforms the CNN, especially when the training data are limited. Finally, the effect of players on the individual violin recognition is investigated.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Gaussian mixture models-universal background model,Identification,individual violin recognition,tonal/nontonal content,violin grade classification},
  file = {/home/hugo/Zotero/storage/XFSLR2HY/Wang and Bao - 2020 - Individual Violin Recognition Method Combining Ton.pdf}
}

@article{wangIndividualViolinRecognition2020a,
  title = {Individual {{Violin Recognition Method Combining Tonal}} and {{Nontonal Features}}},
  author = {Wang, Qi and Bao, Changchun},
  year = {2020},
  month = jun,
  journal = {Electronics},
  volume = {9},
  number = {6},
  pages = {950},
  issn = {2079-9292},
  doi = {10.3390/electronics9060950},
  urldate = {2024-04-24},
  abstract = {Individual recognition among instruments of the same type is a challenging problem and it has been rarely investigated. In this study, the individual recognition of violins is explored. Based on the source--filter model, the spectrum can be divided into tonal content and nontonal content, which reflects the timbre from complementary aspects. The tonal/nontonal gammatone frequency cepstral coefficients (GFCC) are combined to describe the corresponding spectrum contents in this study. In the recognition system, Gaussian mixture models--universal background model (GMM--UBM) is employed to parameterize the distribution of the combined features. In order to evaluate the recognition task of violin individuals, a solo dataset including 86 violins is developed in this study. Compared with other features, the combined features show a better performance in both individual violin recognition and violin grade classification. Experimental results also show the GMM--UBM outperforms the CNN, especially when the training data are limited. Finally, the effect of players on the individual violin recognition is investigated.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/V9SAAIPH/Wang and Bao - 2020 - Individual Violin Recognition Method Combining Ton.pdf}
}

@misc{wiedzminyoDoesWindowingAffect2022,
  type = {Forum Post},
  title = {Does Windowing Affect {{Parseval}}'s Theorem?},
  author = {{wiedzminYo}},
  year = {2022},
  month = apr,
  journal = {Signal Processing Stack Exchange},
  urldate = {2023-12-04}
}

@inproceedings{yokoyamaIdentificationViolinTimbre2022,
  title = {Identification of Violin Timbre by Neural Network Using Acoustic Features},
  booktitle = {Fourth {{Vienna Talk}} on {{Music Acoustics}}},
  author = {Yokoyama, Masao and Ishigaki, Yuya},
  year = {2022},
  pages = {035004},
  address = {University of Music and Performing Arts, Vienna, Austria},
  doi = {10.1121/2.0001659},
  urldate = {2024-03-05},
  langid = {english},
  keywords = {Identification},
  file = {/home/hugo/Zotero/storage/VFPWCNJJ/Yokoyama and Ishigaki - 2022 - Identification of violin timbre by neural network .pdf}
}

@article{yokoyamaIdentificationViolinTimbre2022a,
  title = {Identification of Violin Timbre by Neural Network Using Acoustic Features},
  author = {Yokoyama, Masao and Ishigaki, Yuya},
  year = {2022},
  month = dec,
  journal = {Proceedings of Meetings on Acoustics},
  volume = {49},
  number = {1},
  pages = {035004},
  issn = {1939-800X},
  doi = {10.1121/2.0001659},
  urldate = {2024-04-24},
  abstract = {The timbre of violins is identified using machine learning, and a computer program is developed for the neural network using Python and Keras libraries. The 21 violins recorded include old Italian violins made by Stradivari and contemporary violins. The training and test data use the spectrum envelope and Mel-frequency cepstrum coefficients (MFCC). The accuracy of the identification test in the case of open strings is greater than 90\%. Furthermore, experiments that predict similarity in timbre of an unknown violin to that of trained violins are presented.},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/IV75LWDS/Yokoyama and Ishigaki - 2022 - Identification of violin timbre by neural network .pdf;/home/hugo/Zotero/storage/9YXMFXEZ/Identification-of-violin-timbre-by-neural-network.html}
}

@article{yokoyamaPossibilityDistinctionViolin2020,
  title = {Possibility of Distinction of Violin Timbre by Spectral Envelope},
  author = {Yokoyama, Masao},
  year = {2020},
  month = jan,
  journal = {Applied Acoustics},
  volume = {157},
  pages = {107006},
  issn = {0003-682X},
  doi = {10.1016/j.apacoust.2019.107006},
  urldate = {2024-05-22},
  abstract = {In this study, the sounds of violins, performed by a violinist, were recorded and the distribution of peak frequencies of the spectral envelope of the recorded sound data was analyzed. The distribution of peak frequencies is different for each violin, but some tendencies were found. Questionnaires were used to examine the distinction in violin timbre by the difference in the patterns of peak frequencies. When the patterns of the two violins were similar, the subjects responded that the timbre of both violins was similar than the other violin whose pattern of peak frequencies was different. The present study discussed the contribution of the similarity of patterns and the difference between patterns to the identification of the timbre.},
  keywords = {Detection,Musical acoustic,printed,Spectral envelop,Timbre,Violin},
  file = {/home/hugo/Zotero/storage/NUAQ2NYC/Yokoyama - 2020 - Possibility of distinction of violin timbre by spe.pdf}
}

@article{zanoniPredictionViolinTimbre2017,
  title = {Towards {{Prediction}} of {{Violin Timbre}} from {{Vibrational Measurements}}},
  author = {Zanoni, Massimiliano and Antonacci, Fabio and Sarti, Augusto},
  year = {2017},
  abstract = {This contribution investigates on the acoustics of violin, and more specifically on the relationship existing between vibrational impulse responses and the timbre of the instrument. With respect to previous publications on this topic, we tackle the problem using a feature-based approach. More specifically, we aim at finding the correlation between the features extracted from accelerometric measurements of the bridge mobility and from audio recordings of a prescribed set of performances. Results demonstrate that features describing to the global shape of the spectrum are strongly related. On these descriptors we also show the possibility of predicting the features of audio recordings from the vibrational ones. Experimental data are based on a set of 25 modern violins.},
  langid = {english},
  file = {/home/hugo/Zotero/storage/WKP2FWRB/Zanoni et al. - 2017 - Towards Prediction of Violin Timbre from Vibration.pdf}
}

@article{zhaoViolinistIdentificationUsing2022,
  title = {Violinist {{Identification Using Note-Level Timbre Feature Distributions}}},
  author = {Zhao, Yudong and Fazekas, Gyorgy and Sandler, Mark},
  year = {2022},
  month = may,
  journal = {ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {601--605},
  publisher = {IEEE},
  address = {Singapore, Singapore},
  doi = {10.1109/ICASSP43922.2022.9747606},
  urldate = {2024-04-24},
  abstract = {Modelling musical performers' individual playing styles based on audio features is important for music education, music expression analysis and music generation. In violin performance, the perception of playing styles are mainly affected by the characteristic musical timbre, which is mostly determined by performers, instruments and recording conditions. To verify if timbre features can describe a performer's style adequately, we examine a violinist identification method based on note-level timbre feature distributions. We first apply it using solo datasets to recognise professional violinists, then use it to identify master players from commercial concerto recordings. The results show that the designed features and method work very well for both datasets. The identification accuracy with the solo dataset using MFCCs and spectral constrast features are 0.94 and 0.91 respectively. Significantly lower but promising results are reported with the concerto dataset. Results suggest that the selected timbre features can model performers' individual playing reasonably objectively, regardless of the instrument they play.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {9781665405409},
  keywords = {printed},
  file = {/home/hugo/Zotero/storage/3L9RTE5Y/Zhao et al. - 2022 - Violinist Identification Using Note-Level Timbre F.pdf}
}
